---
title: "Práctica 2: Limpieza y validación de los datos"
author: "Héctor Hernández Membiela"
date: "11/06/2019"
output: 
  pdf_document:
    df_print: kable
    toc: yes
header-includes:
  \renewcommand{\contentsname}{Índice}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set( echo = TRUE )
```

```{r pagebreak-1, results = 'asis', eval = knitr::is_latex_output(), echo = FALSE}
cat( '\\pagebreak' )
```

# 1. Detalles de la actividad  

## 1.1. Descripción  

En esta práctica se elabora un caso práctico orientado a aprender a identificar los datos relevantes para un proyecto analítico y usar las herramientas de integración, limpieza, validación y análisis de las mismas.  

## 1.2. Objetivos  

Los objetivos concretos de esta práctica son:  

* Aprender a aplicar los conocimientos adquiridos y su capacidad de resolución de problemas en entornos nuevos o poco conocidos dentro de contextos más amplios o multidisciplinares.  

* Saber identificar los datos relevantes y los tratamientos necesarios (integración, limpieza y validación) para llevar a cabo un proyecto analítico.  

* Aprender a analizar los datos adecuadamente para abordar la información contenida en los datos.  

* Identificar la mejor representación de los resultados para aportar conclusiones sobre el problema planteado en el proceso analítico.  

* Actuar con los principios éticos y legales relacionados con la manipulación de datos en función del ámbito de aplicación.  

* Desarrollar las habilidades de aprendizaje que les permitan continuar estudiando de un modo que tendrá que ser en gran medida autodirigido o autónomo.  

* Desarrollar la capacidad de búsqueda, gestión y uso de información y recursos en el ámbito de la ciencia de datos.  

## 1.3. Competencias  

En esta práctica se desarrollan las siguientes competencias del Máster de Data Science:  

* Capacidad de analizar un problema en el nivel de abstracción adecuado a cada situación y aplicar las habilidades y conocimientos adquiridos para abordarlo y resolverlo.  

* Capacidad para aplicar las técnicas específicas de tratamiento de datos (integración, transformación, limpieza y validación) para su posterior análisis.  

```{r pagebreak-2, results = 'asis', eval = knitr::is_latex_output(), echo = FALSE}
cat( '\\pagebreak' )
```

# 2. Resolución  

## 2.1. Descripción del dataset.  

El conjunto de datos objeto de análisis es el dataset Titanic, el cual se ha obtenido a partir de este enlace en Kaggle (https://www.kaggle.com/c/titanic).   

El hundimiento del RMS Titanic es, probablemente, el naufragio más famoso de la historia. El 15 de Abril de 1912, durante su viaje inaugural, el Titanic se hundió tras colisionar con un iceberg, muriendo 1502 personas de un total de 2224, contabilizando pasajeros y tripulación.  

Una de las razones por las que el naufragio se cobró tantas vidas fue el no disponer de suficientes botes salvavidas para todos los pasajeros y la tripulación. Aunque la suerte también tuvo su influencia en sobrevivir a la catastrofe, dado que algunas personas tenían más probabilidades de sobrevivir que otras, como mujeres, niños o los pasajeros de primera categoría.  

Así pues, la importancia de este conjunto de datos radica en la capacidad de analizar qué tipo de personas sobrevivieron. Aplicando técnicas de _machine learning_ se busca predecir qué pasajeros sobrevivieron al naufragio.  

## 2.2. Integración y selección de los datos de interés a analizar  

Comenzaremos por la carga del conjunto de datos. Kaggle proporciona los datos divididos en un conjunto de **training** y otro de **test**. Uniremos ambos conjuntos para revisar los datos en su totalidad:  

```{r 2.2, echo = TRUE, message = FALSE, warning = FALSE}
if( !require( dplyr ) ) {
    install.packages( 'dplyr', repos = 'http://cran.us.r-project.org' )
    library( dplyr )
}

train <- read.csv( '../data/titanic-train.csv', stringsAsFactors = F )
test <- read.csv( '../data/titanic-test.csv', stringsAsFactors = F )

full <- bind_rows( train, test )

str( full )
```

Como puede verse en la salida del bloque anterior, el conjunto de datos está constituido por 12 variables (columnas) que presentan 1309 observaciones (filas o registros).  

Entre los campos de este conjunto de datos, encontramos los siguientes:  

Variable   |Descripción
-----------|-----------
PassengerId|Identificador del pasajero
Survived   |Indica si el pasajero sobrevivió (1) o murió (0)
Pclass	   |Categoría en la que viajaba el pasajero
Name	     |Nombre del pasajero
Sex	       |Sexo del pasajero
Age	       |Edad del pasajero
SibSp	     |Número de hermanos o esposas que viajaban a bordo con el pasajero
Parch	     |Número de padres o hijos que viajaban a bordo con el pasajero
Ticket	   |Ticket de embarque
Fare	     |Tarifa
Cabin	     |Cabina asignada
Embarked   |Puerto donde embarcó el pasajero

## 2.3. Limpieza de los datos  

### 2.3.1. ¿Los datos contienen ceros o elementos vacíos?  

Comúnmente, se utilizan los ceros como valor centinela para indicar la ausencia de ciertos valores. Sin embargo, no es el caso de este conjunto de datos puesto que se ha utilizado una combinación del caracter vacío y el valor especial 'NA' para denotar los valores desconocidos.  

Procedemos a conocer a continuación qué campos contienen elementos vacíos. La función **describe** del paquete **Hmisc** nos indica para cada variable del conjunto de datos cuántos valores desconocidos tenemos (campo **missing**):  

```{r 2.3.1-1, echo = TRUE, message = FALSE, warning = FALSE}
if( !require( Hmisc ) ) {
    install.packages( 'Hmisc', repos = 'http://cran.us.r-project.org' )
    library( Hmisc )
}

describe( full )
```

Llegados a este punto debemos decidir cómo manejar estos registros que contienen valores desconocidos para algún campo. Una opción podría ser eliminar los registros que incluyen este tipo de valores, pero ello supondría desaprovechar información. Podemos reemplazar los elementos vacíos con valores extraídos a partir de la distribución de los datos (por ejemplo, la media o la mediana) o podemos utilizar métodos predictivos. Usaremos ambos, apoyándonos en gráficos para decidir qué valor final usar.  

Comenzaremos con los valores perdidos en la variable **Embarked**. Vemos que dichos valores pertenecen a los pasajeros 62 y 830 y que el precio de su pasaje fue de 80$. Estudiaremos las variables **Pclass** y **Fare** para intentar averiguar dónde embarcaron estos pasajeros:  

```{r 2.3.1-2, echo = TRUE, message = FALSE, warning = FALSE}
if( !require( ggplot2 ) ) {
    install.packages( 'ggplot2', repos = 'http://cran.us.r-project.org' )
    library( ggplot2 )
}

if( !require( ggthemes ) ) {
    install.packages( 'ggthemes', repos = 'http://cran.us.r-project.org' )
    library( ggthemes )
}

if( !require( scales ) ) {
    install.packages( 'scales', repos = 'http://cran.us.r-project.org' )
    library( scales )
}

full %>%
    filter( Embarked == "" ) %>%
    select( PassengerId, Fare )

embark_fare <- full %>%
  filter( PassengerId != 62 & PassengerId != 830 )

ggplot( embark_fare, 
        aes( x = Embarked, y = Fare, fill = factor( Pclass ) ) ) +
  geom_boxplot() +
  geom_hline( aes( yintercept = 80 ), colour = 'red', linetype = 'dashed', lwd = 2 ) +
  scale_y_continuous( labels = dollar_format() ) +
  theme_few()
```

Se puede apreciar en el gráfico anterior como los pasajeros de primera que embarcaron en Charbourg ('C') pagaron de media 80$, por tanto, podemos afirmar con bastante seguridad que el valor perdido que buscamos es 'C'.  

```{r 2.3.1-3, echo = TRUE, message = FALSE, warning = FALSE}
full$Embarked[c( 62, 830 )] <- 'C'
```

La información sobre las cabinas no es importante para el estudio que vamos a realizar, por lo que ignoraremos los valores perdidos para este atributo.  

Pasemos ahora a los valores 'NA'. Comenzaremos por el único pasajero sin tarifa asociada:  

```{r 2.3.1-4, echo = TRUE, message = FALSE, warning = FALSE}
full %>%
    filter( is.na( Fare ) )
```

Este pasajero de tercera clase, partió de Southampton ('S'). Vamos a graficar las tarifas de todos aquellos pasajeros que viajaban en la misma clase y partieron del mismo puerto:  

```{r 2.3.1-5, echo = TRUE, message = FALSE, warning = FALSE}
ggplot( full[full$Pclass == '3' & full$Embarked == 'S', ], 
        aes( x = Fare ) ) +
    geom_density( fill = '#99d6ff', alpha = 0.4 ) + 
    geom_vline( aes( xintercept = median( Fare, na.rm = T ) ), 
                colour = 'red', linetype = 'dashed', lwd = 1 ) +
    scale_x_continuous( labels = dollar_format() ) +
    theme_few()
```

Por lo visto en el gráfico, podemos reemplazar el valor perdido por la media de su clase y puerto de embarque.  

```{r 2.3.1-6, echo = TRUE, message = FALSE, warning = FALSE}
full$Fare[1044] <- median( full[full$Pclass == '3' & full$Embarked == 'S', ]$Fare, 
                           na.rm = TRUE )
```

Finalizaremos el tratamiento de los valores perdidos con el campo **Age**. Emplearemos un método de imputación de valores basado en la similitud o diferencia entre los registros: la imputación basada en k vecinos más próximos (en inglés, _kNN-imputation_). La elección de esta alternativa se realiza bajo la hipótesis de que nuestros registros guardan cierta relación.  

```{r 2.3.1-7, echo = TRUE, message = FALSE, warning = FALSE}
if( !require( VIM ) ) {
    install.packages( 'VIM', repos = 'http://cran.us.r-project.org' )
    library( VIM )
}

knn_output <- kNN(full)$Age

par( mfrow = c( 1, 2 ) )
hist( full$Age, freq = F, main = 'Age: Datos Originales', col = 'darkgreen', 
      ylim = c( 0,0.04 ) )
hist( knn_output, freq = F, main = 'Age: Resultados kNN', col = 'lightgreen', 
      ylim = c( 0, 0.04 ) )
```

Comparando los histogramas de los datos originales y del resultado del algoritmo _kNN_, vemos que se puede considerar una aproximación bastante fiable, por lo que reemplazamos los valores originales:  

```{r 2.3.1-8, echo = TRUE, message = FALSE, warning = FALSE}
full$Age <- knn_output
```

**Nota:** los 418 valores 'NA' presentes en la variable **Survived**, se deben a que provienen del conjunto original de test y, por tanto, dicha variable no se proporcionaba. Al utilizar la función **bind_rows**, _R_ ha completado los valores perdidos con valores 'NA'. Dado que esta es la variable a clasificar, no corregiremos los valores 'NA'.  

### 2.3.2. Identificación y tratamiento de valores extremos  

Los valores extremos u _outliers_ son aquellos que parecen no ser congruentes si los comparamos con el resto de los datos. Para identificarlos, podemos hacer uso de dos vías:  

1. Representar un diagrama de caja por cada variable y ver qué valores distan mucho del rango intercuartílico (la caja)
2. Utilizar la función boxplots.stats() de R.  

Optaremos por el segundo método, así, se mostrarán sólo los valores atípicos para aquellas variables que los contienen:  

```{r 2.3.2, echo = TRUE, message = FALSE, warning = FALSE}
lapply( full, function( x ) { if( is.numeric( x ) ) boxplot.stats( x )$out } )
```

Los valores extremos obtenidos para la variable **Age** son perfectamente plausibles para personas de tercera edad. El precio (variable **Fare**) es una entidad variable en función de la demanda y oferta y, por lo que respecta a las variables **SibSp** y **Parch**, si bien algunos valores pueden parecer excesivos, siempre se han dado casos de familias muy numerosas. Es por ello que el manejo de estos valores extremos consistirá en simplemente dejarlos como actualmente están recogidos.

## 2.4. Análisis de los datos  

### 2.4.1. Selección de los grupos de datos que se quieren analizar/comparar  

A continuación, seleccionamos los grupos dentro de nuestro conjunto de datos que pueden resultar interesantes para analizar y/o comparar. Optaremos por aquellas variables de tipo númerico más la variable **Sex**, ya que intuimos que puede ser importante de cara al resultado final.   

```{r 2.4.1, echo = TRUE, message = FALSE, warning = FALSE}
train <- full[1:891,]
test <- full[892:1309,]

str( train )

train.numeric <- dplyr::select_if( train, is.numeric )
train.numeric$Sex <- as.integer( as.factor( train$Sex ) )

test.numeric <- dplyr::select_if( test, is.numeric )
test.numeric$Sex <- as.integer( as.factor( test$Sex ) )

str( train.numeric )
```

### 2.4.2. Comprobación de la normalidad y homogeneidad de la varianza  

Para comprobar que los valores que toman nuestras variables cuantitativas provienen de una población distribuida normalmente, utilizaremos la prueba de normalidad de **Shapiro-Wilk**. Asumiendo como hipótesis nula que la población está distribuida normalmente, si el _p_-valor es menor al nivel de significancia, generalmente $\alpha=0.05$, entonces la hipótesis nula es rechazada y se concluye que los datos no cuentan con una distribución normal. Si, por el contrario, el _p_-valor es mayor a $\alpha$, se concluye que no se puede rechazar dicha hipótesis y se asume que los datos siguen una distribución normal.    

```{r 2.4.2-1, echo = TRUE, message = FALSE, warning = FALSE}
lapply( train.numeric, function( x ) { shapiro.test( x ) } )
```

Dados los resultados del bloque anterior, comprobamos que nuestras variables no siguen una distribución normal.  

Seguidamente, pasamos a estudiar la homogeneidad de varianzas mediante la aplicación de un test de **Fligner-Killeen**. Esta prueba es utilizada cuando los datos no cumplen con la condición de normalidad, extremo este comprobado en el punto anterior. La hipótesis nula asume igualdad de varianzas en los diferentes grupos de datos, por lo que _p_-valores inferiores al nivel de significancia indicarán heterocedasticidad.  

En este caso, estudiaremos esta homogeneidad en cuanto a los grupos conformados por el sexo del pasajero. En el siguiente test, la hipótesis nula consiste en que ambas varianzas son iguales.

```{r 2.4.2-2, echo = TRUE, message = FALSE, warning = FALSE}
fligner.test( Survived~Sex, data = train.numeric )
```

Dado que la prueba resulta en un _p_-valor inferior al nivel de significancia (< 0.05), se rechaza la hipótesis nula de homocedasticidad y se concluye que la variable **Survived** presenta varianzas estadísticamente diferentes para los dos sexos. En otras palabras, hemos comprobado mediante pruebas estadísticas nuestra intuición sobre la influencia de la variable **Sex** en la probabilidad de sobrevivir al hundimiento.  

### 2.4.3. Aplicación de pruebas estadísticas para comparar los grupos de datos.  

#### 2.4.3.1. ¿Qué variables cuantitativas influyen más en la supervivencia?  

Siguiendo el hilo del apartado anterior, procedemos a realizar un análisis de correlación entre las distintas variables para determinar cuáles de ellas ejercen una mayor influencia en la supervivencia al naugragio. Para ello, se utilizará el coeficiente de correlación de **Spearman**, puesto que hemos visto que tenemos datos que no siguen una distribución normal.  

```{r 2.4.3.1, echo = TRUE, message = FALSE, warning = FALSE}
( correlation.matrix <- cor( train.numeric, method = "spearman" ) )
```

Así, identificamos cuáles son las variables más correlacionadas con la probabilidad de sobrevivir en función de su proximidad con los valores -1 y +1. Teniendo esto en cuenta, queda patente cómo la variable
más relevante es **Sex**, seguida de **Pclass** y **Fare**.  

#### 2.4.3.2. ¿Hay diferencias en la probabilidad de sobrevivir entre hombres y mujeres?  

La segunda prueba estadística que se aplicará consistirá en un contraste de hipótesis sobre dos muestras para determinar si la probabilidad de sobrevivir es superior dependiendo del sexo del pasajero. Para ello, tendremos dos muestras: la primera de ellas se corresponderá con los valores para hombres y, la segunda, con aquellos de las mujeres.  

Se debe destacar que un test paramétrico como el que a continuación se utiliza necesita que los datos sean normales, si la muestra es de tamaño inferior a 30. Como en nuestro caso, n > 30, el contraste de hipótesis siguiente es válido.  

```{r 2.4.3.2-1, echo = TRUE, message = FALSE, warning = FALSE}
men.survived <- train.numeric[train.numeric$Sex == 2,]$Survived
women.survived <- train.numeric[train.numeric$Sex == 1,]$Survived
```

Planteamos el siguiente contraste de hipótesis de dos muestras sobre la diferencia de medias, el cual es unilateral atendiendo a la formulación de la hipótesis alternativa:  

$$
\begin{array}{ll}
H_0: \mu_1 - \mu_2 = 0 \\  
H_1: \mu_1 - \mu_2 < 0
\end{array}
$$

donde $\mu_1$ es la media de la población de la que se extrae la primera muestra y $\mu_2$ es la media de la población de la que extrae la segunda. Tomaremos $\alpha = 0,05$.  

```{r 2.4.3.2-2, echo = TRUE, message = FALSE, warning = FALSE}
t.test( men.survived, women.survived, alternative = "less" )
```

Puesto que obtenemos un _p_-valor menor que el valor de significación fijado, rechazamos la hipótesis nula. Por tanto, podemos concluir que, efectivamente, la probabilidad de sobrevivir al naufragio era mayor siendo mujer.  

#### 2.4.3.3. Modelo de regresión lineal  

Tal y como se planteó en los objetivos de la actividad, buscamos predecir qué tipo de pasajeros sobrevivieron a la catástrofe. Así, se calculará un modelo de regresión lineal utilizando regresores cuantitativos con el que poder realizar las predicciones de supervivencia.  

Para obtener un modelo de regresión lineal considerablemente eficiente, lo que haremos será calcular varios modelos de regresión utilizando las variables que estén más correladas con respecto a la variable **Survived**, según la tabla obtenida en el apartado 2.4.3.1. Entre todos los modelos que obtengamos, escogeremos el mejor utilizando como criterio aquel que presente un mayor coeficiente de determinación  ($R^2$).  

```{r 2.4.3.3, echo = TRUE, message = FALSE, warning = FALSE}
model.1 <- lm( Survived ~ Sex, data = train.numeric )
summary( model.1 )
model.2 <- lm( Survived ~ Pclass, data = train.numeric )
summary( model.2 )
model.3 <- lm( Survived ~ Fare, data = train.numeric )
summary( model.3 )
```

En este caso, tenemos que el primer modelo es el más conveniente dado que tiene un mayor coeficiente de determinación. No obstante, dado que el coeficiente de determinación no es muy elevado, vamos a calcular un nuevo modelo utilizando un algoritmo supervisado.  

#### 2.4.3.4. Métodos de clasificación    

En este apartado, vamos a utilizar uno de los métodos de clasificación más sofisticados, el _Random Forest_. Calcularemos primero el modelo y, posteriormente, graficaremos el error del mismo:  

```{r 2.4.3.4-1, echo = TRUE, message = FALSE, warning = FALSE}
if( !require( caret ) ) {
    install.packages( 'caret', repos = 'http://cran.us.r-project.org' )
    library( caret )
}

if( !require( randomForest ) ) {
    install.packages( 'randomForest', repos = 'http://cran.us.r-project.org' )
    library( randomForest )
}

model.rf <- randomForest( factor( Survived ) ~ Pclass + Sex + Age + 
                            SibSp + Parch + Fare, 
                          data = train.numeric, ntree = 100, importance = TRUE )
model.rf

plot( model.rf, ylim = c( 0, 0.36 ), main = "Random Forest" )
legend( 'topright', colnames( model.rf$err.rate ), col = 1:3, fill = 1:3 )

importance <- importance( model.rf )
varImportance <- data.frame( Variables = row.names( importance ), 
                             Importance = round( importance[ ,'MeanDecreaseGini'], 2 ) )

rankImportance <- varImportance %>%
  mutate( Rank = paste0( '#', dense_rank( desc( Importance ) ) ) )

prediction <- predict( model.rf, newdata = test.numeric )
```

En el gráfico, se puede apreciar como el error general se sitúa por debajo del 20%. Es llamativo como, comparando las tasas de error para cada valor de la variable **Survived**, vemos que el modelo es más preciso clasificando las muertes.  

Adicionalmente, en el bloque anterior calculamos la importancia relativa de cada variable en el modelo calculado. Usaremos dichos cálculos en la sección 2.5.3.  

Por último, utilizamos el modelo resultante para predecir la variable **Survived** en el conjunto de _test_. Una vez obtenidas las predicciones, procedemos a completar el conjunto de _test_ y exportamos los datos a un nuevo fichero (**titanic-clean.csv**):    

```{r 2.4.3.4-2, echo = TRUE, message = FALSE, warning = FALSE}
test$Survived <- as.integer( as.character( prediction ) )
full.clean <- bind_rows( train, test )
write.csv( full.clean, "../data/titanic-clean.csv", row.names = FALSE )
```

## 2.5. Representación de los resultados a partir de tablas y gráficas  

### 2.5.1. Ratio de supervivencia por género y categoría  

En el apartado 2.4.3.1. vimos cómo las variables **Sex** y **Pclass** presentaban la mayor correlación con la variable **Survived**. También vimos en el apartado 2.4.2. cómo el hecho de ser mujer significaba una mayor probabilidad de supervivencia. Vamos a visualizar estas afirmaciones a partir de los dados del conjunto de _training_.  

```{r 2.5.1-1, echo = TRUE, message = FALSE, warning = FALSE}
gender <- train %>%
  group_by( Sex ) %>%
  summarise( Count = n() )

gender_ratio <- train %>%
  group_by( Sex, Survived ) %>%
  summarise( Count = n() ) %>%
  mutate( Percentage = round( Count / sum( Count ) * 100 ) )

train %>%
  ggplot() +
  geom_bar( aes( x = Sex, fill = factor( Survived ) ) ) +
  geom_text( data = gender, 
             aes( x = Sex, y = Count, label = Count ), 
             position = position_dodge( width = 0.9 ), 
             vjust = -0.25, 
             fontface = "bold" ) +
  geom_label( data = gender_ratio, 
              aes( x = Sex, y = Count, label = paste0( Percentage, "%" ), 
                   group = Survived ), 
              position = position_stack( vjust = 0.5 ) ) +
  theme_few() +
  theme( plot.title = element_text( hjust = 0.5, size = 18, color = "#054354" ) ) +
  ggtitle( "Titanic - Ratio de supervivientes por género" ) +
  scale_x_discrete( name = "Género" ) +
  scale_y_continuous( name = "Total de pasajeros" ) +
  scale_fill_discrete( name = "Resultado", labels = c( "No sobrevivió", "Sobrevivió" ) )
```

Vemos como el 81% de la población masculina pereció durante el hundimiento del Titanic. En la población femenina, ese porcentaje se reduce al 26%.  

```{r pagebreak-3, results = 'asis', eval = knitr::is_latex_output(), echo = FALSE}
cat( '\\pagebreak' )
```

```{r 2.5.1-2, echo = TRUE, message = FALSE, warning = FALSE}
pclass <- train %>%
  group_by( Pclass ) %>%
  summarise( Count = n() )

pclass_ratio <- train %>%
  group_by( Pclass, Survived ) %>%
  summarise( Count = n() ) %>%
  mutate( Percentage = round( Count / sum( Count ) * 100 ) )

train %>%
  ggplot() +
  geom_bar( aes( x = factor( Pclass ), fill = factor( Survived ) ) ) +
  geom_text( data = pclass, 
             aes( x = factor( Pclass ), y = Count, label = Count ), 
             position = position_dodge( width = 0.9 ), 
             vjust = -0.25, 
             fontface = "bold" ) +
  geom_label( data = pclass_ratio, 
             aes( x = factor( Pclass ), y = Count, label = paste0( Percentage, "%" ), 
                  group = Survived ), 
             position = position_stack( vjust = 0.5 ) ) +
  theme_bw() +
  theme( plot.title = element_text( hjust = 0.5, size = 18, color = "#054354" ) ) +
  ggtitle( "Titanic - Ratio de supervivientes por categoría" ) +
  scale_x_discrete( name = "Categoría" ) +
  scale_y_continuous( name = "Total de pasajeros" ) +
  scale_fill_discrete( name = "Resultado", labels = c( "No sobrevivió", "Sobrevivió" ) )
```

Vemos como el 76% de los pasajeros de tercera categoría no sobrevivieron al naufragio. Ese porcentaje se reduce al 53% para los pasajeros de segunda categoría y al 37% para los de primera.  

```{r pagebreak-4, results = 'asis', eval = knitr::is_latex_output(), echo = FALSE}
cat( '\\pagebreak' )
```

### 2.5.2. ¿Qué variables cuantitativas influyen más en la supervivencia?  

En el apartado 2.4.3.1. vimos la matriz de correlaciones entre nuestra variables cuantitativas. Vamos a visualizar la misma información mediante un gráfico:  

```{r 2.5.2, echo = TRUE, message = FALSE, warning = FALSE}
if( !require( corrplot ) ) {
    install.packages( 'corrplot', repos = 'http://cran.us.r-project.org' )
    library( corrplot )
}

corrplot( correlation.matrix, type = "upper", order = "hclust", tl.col = "black", 
          tl.srt = 45 )
```

```{r pagebreak-5, results = 'asis', eval = knitr::is_latex_output(), echo = FALSE}
cat( '\\pagebreak' )
```

### 2.5.3. Importancia de las variables  

Por último, recuperamos la clasificación sobre la importancia de las variables en el cálculo del modelo usando _Random Forest_ para mostrar dicha información en el siguiente gráfico de barras:  

```{r 2.5.3, echo = TRUE, message = FALSE, warning = FALSE}
ggplot( rankImportance, 
        aes( x = reorder( Variables, Importance ), y = Importance, fill = Importance ) ) +
  geom_bar( stat = 'identity' ) + 
  geom_text( aes( x = Variables, y = 0.5, label = Rank ), 
             hjust = 0, vjust = 0.55, size = 4, colour = 'red' ) +
  labs( x = 'Variables' ) +
  coord_flip() + 
  theme_few()
```

El género del pasajero (**Sex**) se sigue manteniendo como la variable más importante en la predicción de la supervivencia, pero la categoría (**Pclass**) cae el cuarto lugar. La tarifa (**Fare**) escala hasta el segundo.  

```{r pagebreak-6, results = 'asis', eval = knitr::is_latex_output(), echo = FALSE}
cat( '\\pagebreak' )
```

## 2.6. Resolución del problema.  

Se han realizado cuatro tipos de pruebas estadísticas sobre un conjunto de datos que se correspondía con datos relativos a los pasajeros del viaje inaugural del Titanic, con el motivo de cumplir en la medida de lo posible con el objetivo que se planteaba al comienzo. Para cada una de ellas, hemos podido ver cuáles son los resultados que arrojan, mediante tablas y gráficos, y qué conocimientos pueden extraerse a partir de ellas.  

Así, el análisis de correlación y el contraste de hipótesis nos ha permitido conocer cuáles de estas variables ejercen una mayor influencia sobre la posibilidad de sobrevivir al naufragio, mientras que el modelo de clasificación obtenido mediante la aplicación de un _Random Forest_ ha resultado de utilidad a la hora de realizar predicciones para esta variable dadas unas características concretas.  

Previamente, se han sometido los datos a un preprocesamiento para manejar los casos de ceros o elementos vacíos y valores extremos (outliers). Para el caso del primero, se ha hecho uso de un método de imputación de valores de tal forma que no tengamos que eliminar registros del conjunto de datos inicial y que la ausencia de valores no implique llegar a resultados poco certeros en los análisis. Para el caso del segundo, se ha optado por incluir los valores extremos en los análisis dado que parecen no resultar del todo atípicos.  

```{r pagebreak-7, results = 'asis', eval = knitr::is_latex_output(), echo = FALSE}
cat( '\\pagebreak' )
```

# 3. Recursos  

* Calvo M., Subirats L., Pérez D. (2019). Introducción a la limpieza y análisis de los datos. Editorial UOC  

* Megan Squire (2015). Clean Data. Packt Publishing Ltd  

* Jiawei Han, Micheine Kamber, Jian Pei (2012). Data mining: concepts and techniques. Morgan Kaufmann  

* Jason W. Osborne (2010). Data Cleaning Basics: Best Practices in Dealing with Extreme Scores. Newborn and Infant Nursing Reviews; 10 (1): pp. 1527-3369  

* Peter Dalgaard (2008). Introductory statistics with R. Springer Science & Business Media  

* Megan L. Risdal (2016). Exploring survival on the Titanic (https://www.kaggle.com/mrisdal/exploring-survival-on-the-titanic).

```{r pagebreak-8, results = 'asis', eval = knitr::is_latex_output(), echo = FALSE}
cat( '\\pagebreak' )
```

# 4. Contribuciones  

Contribuciones             |Firma
---------------------------|-----
Investigación previa       |HHM
Redacción de las respuestas|HHM
Desarrollo código     	   |HHM